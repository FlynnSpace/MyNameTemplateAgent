from typing import Annotated, Sequence
from openai.types.responses.response_reasoning_item import Summary
from typing_extensions import TypedDict
from dotenv import load_dotenv  
from langchain_core.messages import BaseMessage # The foundational class for all message types in LangGraph
from langchain_core.messages import ToolMessage # Passes data back to LLM after it calls a tool such as the content and the tool_call_id
from langchain_core.messages import SystemMessage # Message for providing instructions to the LLM
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from KIE_tools import *
from tool_prompts import SYSTEM_PROMPT
from pydantic import BaseModel, Field


load_dotenv()

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    last_task_id: str | None
    last_task_config: dict | None

class AgentResponse(BaseModel):
    answer: str = Field(description="The answer to the user's question")
    suggestions: list[str] = Field(description="The suggestions for the user to choose from")

tools = [
    # text_to_image_by_seedream_v4_model_create_task,
    image_edit_by_ppio_banana_pro_create_task,
    get_task_status,
    get_ppio_task_status,
    text_to_video_by_kie_sora2_create_task,
    first_frame_to_video_by_kie_sora2_create_task,
    remove_watermark_from_image_by_kie_seedream_v4_create_task
    ]  # max function name length is 64

llm = ChatOpenAI(model = "gpt-5-nano",
                 temperature=0.0)

structured_llm = llm.with_structured_output(
    schema=AgentResponse,
    method="json_schema",
    strict=True,
    tools=tools,
    include_raw=True,
    reasoning_effort="medium"  # Can be "low", "medium", or "high"
    )


def recorder_node(state: AgentState):
    """è®°å½•å™¨èŠ‚ç‚¹ï¼šä»å·¥å…·æ‰§è¡Œç»“æœä¸­æå–çŠ¶æ€"""
    messages = state["messages"]
    new_state = {}
    
    # å€’åºéå†å¯»æ‰¾æœ€è¿‘çš„ AIMessage (è·å–å‚æ•°)
    last_ai_message = None
    for msg in reversed(messages):
        # æ£€æŸ¥æ˜¯å¦æ˜¯ AI æ¶ˆæ¯ä¸”æœ‰ tool_calls
        if msg.type == "ai" and hasattr(msg, "tool_calls") and msg.tool_calls:
            last_ai_message = msg
            break
            
    if not last_ai_message:
        return {}

    # å»ºç«‹ ID åˆ°å‚æ•°çš„æ˜ å°„
    call_id_to_args = {call["id"]: call["args"] for call in last_ai_message.tool_calls}
    call_id_to_name = {call["id"]: call["name"] for call in last_ai_message.tool_calls}

    # å€’åºæŸ¥æ‰¾æœ€è¿‘çš„ ToolMessage
    for msg in reversed(messages):
        if msg.type == "tool":
            tool_call_id = msg.tool_call_id
            if tool_call_id in call_id_to_args:
                tool_name = call_id_to_name[tool_call_id]
                
                # åªæœ‰ç”Ÿæˆç±»ä»»åŠ¡æ‰éœ€è¦è®°å½•
                if "create_task" in tool_name:
                    # æå– ID (content) å’Œ Config (args)
                    new_state["last_task_id"] = str(msg.content)
                    new_state["last_task_config"] = call_id_to_args[tool_call_id]
                    break # åªè®°å½•æœ€è¿‘çš„ä¸€ä¸ª
        elif msg.type == "ai":
            # é‡åˆ° AI æ¶ˆæ¯åœæ­¢ï¼Œè¯´æ˜è¿™è½® Tool æ‰§è¡Œçš„æ¶ˆæ¯å·²ç»éå†å®Œäº†
            break
            
    return new_state


def model_call(state:AgentState) -> AgentState:
    # 1. æ³¨å…¥åŠ¨æ€ä¸Šä¸‹æ–‡
    context_str = ""
    if state.get("last_task_id"):
        context_str += f"\n[MEMORY] Last Task ID: {state['last_task_id']}"
    if state.get("last_task_config"):
        context_str += f"\n[MEMORY] Last Task Config: {state['last_task_config']}"
        
    # 2. ç»„åˆ Prompt
    system_prompt = SystemMessage(content=SYSTEM_PROMPT.format(tools_description=str(tools)) + context_str)
    
    # 3. è°ƒç”¨æ¨¡å‹
    response = structured_llm.invoke([system_prompt] + state["messages"])
    raw_response = response["raw"]
    return {"messages": [raw_response]}


def should_continue(state: AgentState): 
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­è°ƒç”¨å·¥å…·"""
    messages = state["messages"]
    last_message = messages[-1]
    if hasattr(last_message, 'tool_calls') and not last_message.tool_calls: 
        return "end"
    else:
        return "continue"
    

graph = StateGraph(AgentState)
graph.add_node("our_agent", model_call)


tool_node = ToolNode(tools=tools)
graph.add_node("tools", tool_node)
graph.add_node("recorder", recorder_node)

graph.set_entry_point("our_agent")

graph.add_conditional_edges(
    "our_agent",
    should_continue,
    {
        "continue": "tools",
        "end": END,
    },
)

graph.add_edge("tools", "recorder")
graph.add_edge("recorder", "our_agent")

app = graph.compile()

def print_stream(stream):
    for s in stream:
        message = s["messages"][-1]
        if isinstance(message, tuple):
            print(message)
        else:
            message.pretty_print()


async def chat_async():
    """æŒç»­å¯¹è¯æ¨¡å¼ - Tokençº§æµå¼è¾“å‡º"""
    from langchain_core.messages import AIMessage, HumanMessage
    
    # æ¬¢è¿ç•Œé¢
    print("\n" + "=" * 60)
    print("ğŸ¬  AI è§†é¢‘/å›¾åƒç”ŸæˆåŠ©æ‰‹ - ã€Šä½ çš„åå­—ã€‹ç»­é›†æ¨¡æ¿")
    print("=" * 60)
    
    # AI çš„å¼€åœºç™½
    greeting = ("ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ AI åˆ›ä½œåŠ©æ‰‹ã€‚\n"
                "æˆ‘å¯ä»¥å¸®ä½ åŸºäºã€Šä½ çš„åå­—ã€‹åˆ›ä½œç»­é›†å†…å®¹ï¼š\n"
                "ğŸ“· æ ¹æ®è§’è‰²å‚è€ƒå›¾ç”Ÿæˆæ–°å›¾åƒ\n"
                "ğŸ¬ é€šè¿‡æ–‡æœ¬æˆ–é¦–å¸§ç”Ÿæˆè§†é¢‘\n"
                "è¾“å…¥ 'é€€å‡º' æˆ– 'exit' ç»“æŸå¯¹è¯ã€‚")
    
    # åˆå§‹åŒ– AgentState
    state: AgentState = {"messages": [AIMessage(content=greeting)]}
    print(f"\nAI: {greeting}\n")
    
    while True:
        user_input = input("ä½ : ")
        
        # æ£€æŸ¥é€€å‡ºå‘½ä»¤
        if user_input.lower().strip() in ["é€€å‡º", "exit", "quit", "ç»“æŸ", "å†è§"]:
            print("\nAI: å†è§ï¼æœŸå¾…ä¸‹æ¬¡ä¸ºä½ åˆ›ä½œç²¾å½©å†…å®¹ã€‚ğŸ‘‹\n")
            break
        
        # æ£€æŸ¥ç©ºè¾“å…¥
        if not user_input.strip():
            print("AI: è¯·è¾“å…¥æœ‰æ•ˆçš„å†…å®¹ã€‚\n")
            continue
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ° state
        state["messages"].append(HumanMessage(content=user_input))
        
        # ä½¿ç”¨ Token çº§æµå¼è¾“å‡º
        print()
        
        # è·Ÿè¸ªçŠ¶æ€
        in_agent_response = False
        shown_ai_prefix = False
        
        # ä½¿ç”¨ astream_events å®ç° Token çº§æµå¼ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
        async for event in app.astream_events(state, version="v2"):
            kind = event["event"]
            
            # æ•è· LLM çš„æµå¼ token
            if kind == "on_chat_model_stream":
                content = event["data"]["chunk"].content
                if content:
                    if not shown_ai_prefix:
                        print("AI: ", end="", flush=True)
                        shown_ai_prefix = True
                    print(content, end="", flush=True)
                    in_agent_response = True
            
            # æ•è·å·¥å…·è°ƒç”¨ä¿¡æ¯
            elif kind == "on_tool_start":
                tool_name = event["name"]
                if in_agent_response:
                    print()  # æ¢è¡Œ
                    in_agent_response = False
                print(f"\n[ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}]", flush=True)
                shown_ai_prefix = False  # é‡ç½®ï¼Œä¸‹æ¬¡æ¨¡å‹è¾“å‡ºæ—¶å†æ˜¾ç¤º
            
            elif kind == "on_tool_end":
                print(f"[âœ“ å·¥å…·æ‰§è¡Œå®Œæˆ]\n", flush=True)
                in_agent_response = False
            
            # æ•è·æœ€ç»ˆçŠ¶æ€æ›´æ–°
            elif kind == "on_chain_end" and event.get("name") == "LangGraph":
                # è·å–æœ€ç»ˆè¾“å‡ºçŠ¶æ€
                state = event["data"]["output"]
        
        print("\n")  # ç©ºè¡Œåˆ†éš”


def chat():
    """åŒæ­¥åŒ…è£…å™¨ - è°ƒç”¨å¼‚æ­¥ chat å‡½æ•°"""
    import asyncio
    
    try:
        asyncio.run(chat_async())
    except KeyboardInterrupt:
        print("\n\nç¨‹åºå·²ä¸­æ–­ã€‚å†è§ï¼")


if __name__ == "__main__":
    chat()
