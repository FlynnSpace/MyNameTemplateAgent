import json
from typing import Annotated, Sequence
from openai.types.responses.response_reasoning_item import Summary
from typing_extensions import TypedDict
from dotenv import load_dotenv  
from langchain_core.messages import BaseMessage # The foundational class for all message types in LangGraph
from langchain_core.messages import ToolMessage # Passes data back to LLM after it calls a tool such as the content and the tool_call_id
from langchain_core.messages import SystemMessage # Message for providing instructions to the LLM
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from KIE_tools import *
# Explicitly import helper functions since 'from KIE_tools import *' skips underscores
from KIE_tools import _get_ppio_task_status_impl, _get_kie_task_status_impl 
from tool_prompts import Custom_SYSTEM_PROMPT
from pydantic import BaseModel, Field
from logger_util import get_logger



load_dotenv()
logger = get_logger("customchat.agent")


def log_system_message(message: str, echo: bool = False) -> None:
    """Helper to log a system-level message and optionally echo to console."""
    logger.info(message)
    if echo:
        print(message)


def prepare_state_from_payload(query_json: dict, state: "AgentState") -> "AgentState":
    """
    éƒ¨ç½²/æœ¬åœ°é€šç”¨çš„è¾“å…¥é¢„å¤„ç†ï¼š
    - è§£æ user_query ä¸ references
    - å†™å…¥ messages
    - æ‰“æ—¥å¿—ï¼ˆlog_system_message ä¼šåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°ä¸æ–‡ä»¶ï¼‰
    """
    query = query_json.get("user_query", "")
    refs = query_json.get("references", [])

    state["references"] = refs
    
    if query:
        state.setdefault("messages", []).append(HumanMessage(content=query))
        log_system_message(f"[INPUT] JSON è§£ææˆåŠŸ - query: {query[:50]}{'...' if len(query) > 50 else ''}", echo=False)
    else:
        log_system_message("[INPUT] Query ä¸ºç©ºï¼Œè·³è¿‡æ·»åŠ  HumanMessage (å¯èƒ½æ˜¯ State ä¼ é€’)", echo=False)

    log_system_message(f"[INPUT] references æ•°é‡: {len(refs)}", echo=False)
    if refs:
        for i, ref in enumerate(refs):
            log_system_message(f"[INPUT]   [{i+1}] url: {ref.get('url', 'N/A')[:80]}", echo=False)
    else:
        log_system_message("[INPUT]   (ç©ºåˆ—è¡¨)", echo=False)
    log_system_message(f"[INPUT] last_task_id: {state.get('last_task_id', 'None')}", echo=False)
    log_system_message(f"[INPUT] last_tool_name: {state.get('last_tool_name', 'None')}", echo=False)

    return state

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    last_task_id: str | None  # è®°å½•æœ€è¿‘ä¸€ä¸ªä»»åŠ¡çš„IDï¼Œç”¨äºç¼–è¾‘å›¾åƒæ—¶ï¼Œå¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šURLï¼Œä¸”æ²¡æœ‰æåˆ°retryï¼Œåˆ™ä½¿ç”¨æ­¤å€¼è¿›è¡ŒæŸ¥è¯¢
    last_tool_name: str | None # è®°å½•æœ€è¿‘ä¸€ä¸ªä»»åŠ¡ä½¿ç”¨çš„å·¥å…·åç§°ï¼Œç”¨äºåŒºåˆ†get_kie_task_statuså’Œget_ppio_task_status
    last_task_config: dict | None  # è®°å½•æœ€è¿‘ä¸€ä¸ªä»»åŠ¡çš„é…ç½®ï¼Œç”¨äºç¼–è¾‘å›¾åƒæ—¶ï¼Œå¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šURLï¼Œä¸”è¯´RETRYåˆ™ä½¿ç”¨æ­¤å€¼è¿›è¡Œé‡æ–°ç”Ÿæˆ
    global_config: dict | None  # è®°å½•å…¨å±€é…ç½®ï¼Œç”¨äºå‚¨å­˜æ¨¡æ¿çš„é…ç½®ï¼Œç”¨äºagentçš„èƒŒæ™¯çŸ¥è¯†å¡«å…¥APIè°ƒç”¨å‚æ•°
    references: list[dict] | None  # è®°å½•å‚è€ƒç´ æï¼Œæœ‰URLæ—¶è´Ÿè´£è®°å½•ï¼Œæ— URLæ—¶è´Ÿè´£æŒ‡ä»£å‚è€ƒç´ æ
    model_call_count: int  # è®°å½•å•è½®äº¤äº’ä¸­ model_call çš„æ‰§è¡Œæ¬¡æ•°


class AgentResponse(BaseModel):
    answer: str = Field(description="The answer to the user's question")
    suggestions: list[str] = Field(description="The suggestions for the user to choose from")


tools = [
    # text_to_image_by_seedream_v4_model_create_task,
    image_edit_by_ppio_banana_pro_create_task,
    # get_task_status,
    text_to_video_by_kie_sora2_create_task,
    first_frame_to_video_by_kie_sora2_create_task,
    remove_watermark_from_image_by_kie_seedream_v4_create_task
    ]  # max function name length is 64

llm = ChatOpenAI(model = "gpt-5-nano",
                 temperature=0.0)

structured_llm = llm.with_structured_output(
    schema=AgentResponse,
    method="json_schema",
    strict=True,
    tools=tools,
    include_raw=True,
    reasoning_effort="medium"  # Can be "low", "medium", or "high"
    )


def initial_prep_node(input_dict: dict) -> AgentState:
    """
    å›¾çš„ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼šå°†å¤–éƒ¨åŸå§‹è¾“å…¥ (input_dict) è½¬æ¢ä¸º AgentStateã€‚
    LangGraph Server éƒ¨ç½²æ—¶ï¼ŒHTTP è¯·æ±‚ä½“è§£æåçš„å­—å…¸ä¼šä½œä¸º input_dict ä¼ å…¥ã€‚
    """
    # 1. åªéœ€è¦å¤„ç†æœ¬æ¬¡è¯·æ±‚ç›¸å…³çš„å­—æ®µ (messages, references)
    # ä¸è¦é‡ç½® last_task_id ç­‰æŒä¹…åŒ–å­—æ®µï¼Œå¦åˆ™ä¼šä¸¢å¤±å†å²çŠ¶æ€
    partial_state = {
        "references": [],
        "model_call_count": 0, # æ¯æ¬¡æ–°ç”¨æˆ·è¾“å…¥ï¼Œé‡ç½®è®¡æ•°å™¨
        # "last_task_id": None,  <-- ç§»é™¤è¿™äº›é‡ç½®æ“ä½œ
        # "last_tool_name": None,
        # "last_task_config": None,
        # "global_config": None
    }
    
    # 2. è°ƒç”¨é¢„å¤„ç†é€»è¾‘ï¼Œè§£æè¾“å…¥å¹¶å¡«å…¥ partial_state
    return prepare_state_from_payload(input_dict, partial_state)


def recorder_node(state: AgentState) -> AgentState:
    """è®°å½•å™¨èŠ‚ç‚¹ï¼šä»å·¥å…·æ‰§è¡Œç»“æœä¸­æå–çŠ¶æ€å’Œæ›´æ–° References"""
    messages = state["messages"]
    new_state = {}
    
    log_system_message("--- [DEBUG] Entering recorder_node ---", echo=False)
    
    # å€’åºéå†å¯»æ‰¾æœ€è¿‘çš„ AIMessage (è·å–å‚æ•°)
    last_ai_message = None
    for msg in reversed(messages):
        # æ£€æŸ¥æ˜¯å¦æ˜¯ AI æ¶ˆæ¯ä¸”æœ‰ tool_calls
        if msg.type == "ai" and hasattr(msg, "tool_calls") and msg.tool_calls:
            last_ai_message = msg
            break
            
    if not last_ai_message:
        log_system_message("--- [DEBUG] Recorder: No AI message with tool_calls found.", echo=False)
        return {}

    # å»ºç«‹ ID åˆ°å‚æ•°çš„æ˜ å°„
    call_id_to_args = {call["id"]: call["args"] for call in last_ai_message.tool_calls}
    call_id_to_name = {call["id"]: call["name"] for call in last_ai_message.tool_calls}
    
    log_system_message(f"--- [DEBUG] Found Tool Calls: {list(call_id_to_name.values())}", echo=False)

    # å€’åºæŸ¥æ‰¾æœ€è¿‘çš„ ToolMessage
    for msg in reversed(messages):
        if msg.type == "tool":
            tool_call_id = msg.tool_call_id
            
            # åªå¤„ç†å±äºå½“å‰ AI æ¶ˆæ¯çš„ ToolMessage
            if tool_call_id in call_id_to_args:
                tool_name = call_id_to_name[tool_call_id]
                log_system_message(f"--- [DEBUG] Processing ToolMessage for: {tool_name}", echo=False)
                
                # 1. å¦‚æœæ˜¯ç”Ÿæˆç±»ä»»åŠ¡ -> è®°å½• ID, Config, ToolName
                if "create_task" in tool_name:
                    task_payload = msg.content
                    log_system_message(f"--- [DEBUG] Raw Payload: {task_payload}", echo=False)
                    
                    task_id = None
                    if isinstance(task_payload, dict):
                        task_id = task_payload.get("task_id") or task_payload.get("id")
                    elif isinstance(task_payload, str):
                        candidate = task_payload.strip()
                        if candidate.startswith("{") and candidate.endswith("}"):
                            try:
                                parsed = json.loads(candidate)
                                task_id = parsed.get("task_id") or parsed.get("id")
                            except json.JSONDecodeError:
                                task_id = candidate
                        else:
                            task_id = candidate
                    elif task_payload:
                        task_id = str(task_payload)

                    if not task_id:
                        log_system_message(f"--- [DEBUG] âŒ FAILED to extract task_id", echo=False)
                        logger.warning("Recorder: tool %s returned no task_id payload=%s", tool_name, task_payload)
                        continue

                    log_system_message(f"--- [DEBUG] âœ… CAPTURED task_id: {task_id}, tool_name: {tool_name}, config: {call_id_to_args[tool_call_id]}", echo=False)
                    logger.info("Recorder captured task %s via tool %s", task_id, tool_name)
                    
                    new_state["last_task_id"] = task_id
                    new_state["last_tool_name"] = tool_name
                    new_state["last_task_config"] = call_id_to_args[tool_call_id]

                    break 
                        
    return new_state


def model_call(state:AgentState) -> AgentState:
    """æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹ï¼šè´Ÿè´£æ„å»º Prompt å¹¶è°ƒç”¨ LLMï¼ŒåŒæ—¶å¤„ç†è‡ªåŠ¨åŠ è½½é€»è¾‘"""

    def _snapshot(tag: str):
        refs = state.get("references") or []
        log_system_message(
            f"[STATE:{tag}] msgs={state.get('messages')}, \n================================================\n"
            f"refs={state.get('references')},"
            f"last_task_id={state.get('last_task_id')}, last_tool_name={state.get('last_tool_name')}",          
            echo=False,
        )
    _snapshot("enter")
    
    # --- è®¡æ•°å™¨è‡ªå¢ ---
    current_count = state.get("model_call_count", 0) + 1
    log_system_message(f"[Step] Model Call Count: {current_count}", echo=False)

    # --- è‡ªåŠ¨åŠ è½½ä¸Šä¸€è½®ç”Ÿæˆç»“æœ (Auto-Load Logic) ---
    # ä¿ç•™è‡ªåŠ¨æŸ¥è¯¢ï¼šå³ä½¿å‰ç«¯ä¹Ÿä¼šä¼ å› URLï¼Œæˆ‘ä»¬ä»æä¾›"æ— æ„ŸçŸ¥å…œåº•"ä½“éªŒï¼Œ
    # å°¤å…¶åœ¨ç”¨æˆ·è¿ç»­ç¼–è¾‘ã€æ²¡æœ‰é€‰æ‹© ref æ—¶ï¼Œå¯ä»¥è‡ªåŠ¨æŸ¥è¯¢ä¸Šä¸€è½®ä»»åŠ¡ç»“æœï¼Œå‡è½»äººå·¥æ“ä½œ
    
    current_refs = state.get("references", [])
    last_tid = state.get("last_task_id")
    last_tool = state.get("last_tool_name")
    
    # å¦‚æœå½“å‰æ²¡æœ‰å¼•ç”¨ï¼Œä¸”æœ‰ä¸Šä¸€è½®ä»»åŠ¡ï¼Œä¸”ä¸Šä¸€è½®æ˜¯å›¾åƒç¼–è¾‘ä»»åŠ¡ï¼Œå°è¯•è‡ªåŠ¨åŠ è½½
    # é˜²å¾¡ï¼šç¡®ä¿ last_tool ä¸ä¸º None ä¸”ç¡®å®æ˜¯å·¥å…·è°ƒç”¨
    # ä¼˜åŒ–ï¼šåªåœ¨é¦–è½®æ€è€ƒ (current_countä¸ºåŸºæ•°ä»£è¡¨agentå·²ç»æ‰§è¡Œè¿‡tool) æ—¶åŠ è½½ï¼Œé¿å…åœ¨å·¥å…·æ‰§è¡Œåçš„æ€»ç»“é˜¶æ®µé‡å¤åŠ è½½
    if current_count%2 == 1 and not current_refs and last_tid and last_tool:
        if "image_edit" in last_tool.lower():
            fetched_url = None
            log_system_message(f"[ç³»ç»Ÿ] å°è¯•è‡ªåŠ¨åŠ è½½ä¸Šä¸€è½®ä»»åŠ¡ç»“æœ (ID: {last_tid})...", echo=False)
            
            # æ ¹æ® Last Tool Name å†³å®šè°ƒç”¨å“ªä¸ªæŸ¥è¯¢å‡½æ•° (å¤ç”¨ KIE_tools å†…éƒ¨é€»è¾‘)
            if "ppio" in last_tool.lower() or "banana" in last_tool.lower():
                try:
                    res = _get_ppio_task_status_impl(last_tid)
                    if isinstance(res, str) and res.startswith("http"):
                        fetched_url = res
                    log_system_message(f"PPIO æŸ¥è¯¢æˆåŠŸ: {fetched_url}", echo=False)
                except Exception as e:
                    log_system_message(f"[ç³»ç»Ÿ] PPIO æŸ¥è¯¢å¤±è´¥: {e}", echo=False)
            else:
                try:
                    res = _get_kie_task_status_impl(last_tid)
                    if isinstance(res, str) and res.startswith("http"):
                        fetched_url = res
                    log_system_message(f"KIE æŸ¥è¯¢æˆåŠŸ: {fetched_url}", echo=False)
                except Exception as e:
                     log_system_message(f"[ç³»ç»Ÿ] KIE æŸ¥è¯¢å¤±è´¥: {e}", echo=False)
            
            if fetched_url:
                log_system_message(f"[ç³»ç»Ÿ] âœ… æˆåŠŸåŠ è½½ä¸Šä¸€è½®ç»“æœ: {fetched_url}", echo=False)
                # ç›´æ¥æ›´æ–° stateï¼Œæœ¬è½®ç”Ÿæ•ˆï¼›å› ä¸ºä¸è¿”å›ï¼Œæ‰€ä»¥ä¸ä¼šæŒä¹…åŒ–åˆ°ä¸‹ä¸€è½®
                state["references"] = [{"url": fetched_url, "desc": "Last Generation Result (Auto-loaded)"}]
                
                # --- ç®€å•ç²—æš´ï¼šHack ç”¨æˆ· Promptï¼Œå¼ºåˆ¶ Agent æ³¨æ„åˆ°è¿™å¼ å›¾ ---
                messages = state["messages"]
                if messages and isinstance(messages[-1], HumanMessage):
                    original_content = messages[-1].content
                    # é¿å…é‡å¤æ·»åŠ 
                    if "ç³»ç»Ÿè‡ªåŠ¨æ³¨å…¥" not in original_content:
                        new_content = f"ï¼ˆç³»ç»Ÿè‡ªåŠ¨æ³¨å…¥ï¼šè¯·ä½¿ç”¨ä¸Šä¸€æ¬¡çš„ç¼–è¾‘ç»“æœ {fetched_url} ä½œä¸ºå‚è€ƒå›¾ã€‚ï¼‰\n" + original_content
                        messages[-1].content = new_content
                        log_system_message(f"[Hack] ä¿®æ”¹ç”¨æˆ· Prompt: {new_content[:100]}...", echo=False)
            else:
                log_system_message("[ç³»ç»Ÿ] â³ ä¸Šä¸€è½®ä»»åŠ¡ä»åœ¨å¤„ç†ä¸­æˆ–æ— æ³•è·å–ç»“æœã€‚", echo=False)
        else:
            log_system_message(f"è·³è¿‡è‡ªåŠ¨åŠ è½½: refs={current_refs} last_tid={last_tid} last_tool={last_tool}", echo=False)

    # 1. æ³¨å…¥åŠ¨æ€ä¸Šä¸‹æ–‡
    context_str = ""
    
    # æ³¨å…¥ç´ æåº“ (ä½¿ç”¨æœ¬è½®çš„ referencesï¼Œå¯èƒ½æ¥è‡ªç”¨æˆ·è¾“å…¥æˆ–è‡ªåŠ¨åŠ è½½)
    if state.get("references"):
        context_str += "\n### [REFERENCES]\n"
        for idx, asset in enumerate(state["references"]):
            context_str += f"{idx+1}. {asset.get('desc', 'Image')}: {asset.get('url')}\n"

    # æ³¨å…¥å…¨å±€é£æ ¼é…ç½®
    if state.get("global_config"):
        import json
        context_str += f"\n### [GLOBAL CONFIG]\n{json.dumps(state['global_config'], ensure_ascii=False)}\n"
        context_str += "INSTRUCTION: Always reference these parameters (resolution, aspect_ratio, art_style, etc.) when calling tools unless the user explicitly overrides them in query.\n"

    # [MEMORY] åŒºå—å·²åœ¨ System Prompt ä¸­ç§»é™¤å®šä¹‰ï¼Œæ­¤å¤„ä¸å†æ³¨å…¥ï¼ŒèŠ‚çœ Token
    # if state.get("last_task_id"):
    #     context_str += f"\n[MEMORY] Last Task ID: {state['last_task_id']}"
    # if state.get("last_task_config"):
    #     context_str += f"\n[MEMORY] Last Task Config: {state['last_task_config']}"
    
    # --- HERE IS THE CHANGE: Use Custom_SYSTEM_PROMPT ---
    # 2. ç»„åˆ Prompt
    system_prompt = SystemMessage(content=Custom_SYSTEM_PROMPT.format(tools_description=str(tools)) + context_str)
    
    # 3. è°ƒç”¨æ¨¡å‹
    response = structured_llm.invoke([system_prompt] + state["messages"])
    raw_response = response["raw"]
    
    # åªè¿”å› messagesï¼Œä¸è¿”å› references
    # references ä¼šåœ¨æœ¬è½®ä½¿ç”¨åï¼Œç”± recorder_node å¼ºåˆ¶æ¸…ç©ºï¼Œé¿å…æŒä¹…åŒ–åˆ°ä¸‹ä¸€è½®
    _snapshot("exit")
    return {
        "messages": [raw_response], 
        "model_call_count": current_count,
#        "references": [],
#        "last_task_id": None,
#        "last_tool_name": None,
#        "last_task_config": None,
#        "global_config": None,
        }


def should_continue(state: AgentState): 
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­è°ƒç”¨å·¥å…·"""
    messages = state["messages"]
    last_message = messages[-1]
    if hasattr(last_message, 'tool_calls') and not last_message.tool_calls: 
        return "end"
    else:
        return "continue"
    

graph = StateGraph(AgentState)
graph.add_node("our_agent", model_call)
graph.add_node("initial_prep", initial_prep_node)

tool_node = ToolNode(tools=tools)
graph.add_node("tools", tool_node)
graph.add_node("recorder", recorder_node)

graph.set_entry_point("initial_prep")
graph.add_edge("initial_prep", "our_agent")

graph.add_conditional_edges(
    "our_agent",
    should_continue,
    {
        "continue": "tools",
        "end": END,
    },
)

graph.add_edge("tools", "recorder")
graph.add_edge("recorder", "our_agent")


app = graph.compile()

def print_stream(stream):
    for s in stream:
        message = s["messages"][-1]
        if isinstance(message, tuple):
            print(message)
        else:
            message.pretty_print()


async def chat_async():
    """æŒç»­å¯¹è¯æ¨¡å¼ - Tokençº§æµå¼è¾“å‡º"""
    from langchain_core.messages import AIMessage, HumanMessage
    
    # æ¬¢è¿ç•Œé¢
    print("\n" + "=" * 60)
    print("ğŸ¬  AI è§†é¢‘/å›¾åƒç”ŸæˆåŠ©æ‰‹")
    print("=" * 60)
    
    # AI çš„å¼€åœºç™½
    greeting = ("ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ AI åˆ›ä½œåŠ©æ‰‹ã€‚\n"
                "æˆ‘å¯ä»¥å¸®ä½ åŸºäºä»»ä½•ç´ æåˆ›ä½œç»­é›†å†…å®¹ï¼š\n"
                "ğŸ“· æ ¹æ®è§’è‰²å‚è€ƒå›¾ç”Ÿæˆæ–°å›¾åƒ\n"
                "ğŸ¬ é€šè¿‡æ–‡æœ¬æˆ–é¦–å¸§ç”Ÿæˆè§†é¢‘\n"
                "è¾“å…¥ 'é€€å‡º' æˆ– 'exit' ç»“æŸå¯¹è¯ã€‚")
    
    # åˆå§‹åŒ– AgentState
    state: AgentState = {"messages": [AIMessage(content=greeting)]}
    print(f"\nAI: {greeting}\n")
    
    while True:
        user_input = input("ä½ : ")
        
        # é€€å‡ºæ£€æµ‹
        if user_input.lower() in ["exit", "quit", "é€€å‡º"]:
            print("ğŸ‘‹ å†è§ï¼")
            break
        if not user_input.strip():
            continue

        log_system_message(f"[INPUT] ç”¨æˆ·è¾“å…¥: {user_input[:100]}{'...' if len(user_input) > 100 else ''}", echo=False)
        # å°è¯•è§£æ JSON è¾“å…¥ï¼ˆé€šç”¨é¢„å¤„ç†ï¼‰
        try:
            input_data = json.loads(user_input)
            state = prepare_state_from_payload(input_data, state)

        except json.JSONDecodeError:
            # æ™®é€šæ–‡æœ¬è¾“å…¥ -> æ¸…ç©ºä¸Šä¸€è½®çš„å‚è€ƒç´ æ
            state["references"] = []
            log_system_message("[INPUT] çº¯æ–‡æœ¬è¾“å…¥ (é JSON)", echo=False)
            log_system_message("[INPUT] references: [] (å·²æ¸…ç©º)", echo=False)
            log_system_message(f"[INPUT] last_task_id: {state.get('last_task_id', 'None')}", echo=False)
            log_system_message(f"[INPUT] last_tool_name: {state.get('last_tool_name', 'None')}", echo=False)
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            state["messages"].append(HumanMessage(content=user_input))
        
        # ä½¿ç”¨ Token çº§æµå¼è¾“å‡º
        print()
        
        # è·Ÿè¸ªçŠ¶æ€
        in_agent_response = False
        shown_ai_prefix = False
        
        # ä½¿ç”¨ astream_events å®ç° Token çº§æµå¼ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
        async for event in app.astream_events(state, version="v2"):
            kind = event["event"]
            
            # æ•è· LLM çš„æµå¼ token
            if kind == "on_chat_model_stream":
                content = event["data"]["chunk"].content
                if content:
                    if not shown_ai_prefix:
                        print("AI: ", end="", flush=True)
                        shown_ai_prefix = True
                    print(content, end="", flush=True)
                    in_agent_response = True
            
            # æ•è·å·¥å…·è°ƒç”¨ä¿¡æ¯
            elif kind == "on_tool_start":
                tool_name = event["name"]
                if in_agent_response:
                    print()  # æ¢è¡Œ
                    in_agent_response = False
                print(f"\n[ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}]", flush=True)
                shown_ai_prefix = False  # é‡ç½®ï¼Œä¸‹æ¬¡æ¨¡å‹è¾“å‡ºæ—¶å†æ˜¾ç¤º
            
            elif kind == "on_tool_end":
                print(f"[âœ“ å·¥å…·æ‰§è¡Œå®Œæˆ]\n", flush=True)
                in_agent_response = False
            
            # æ•è·æœ€ç»ˆçŠ¶æ€æ›´æ–°
            elif kind == "on_chain_end" and event.get("name") == "LangGraph":
                # è·å–æœ€ç»ˆè¾“å‡ºçŠ¶æ€
                state = event["data"]["output"]
        
        print("\n")  # ç©ºè¡Œåˆ†éš”


def chat():
    """åŒæ­¥åŒ…è£…å™¨ - è°ƒç”¨å¼‚æ­¥ chat å‡½æ•°"""
    import asyncio
    
    try:
        asyncio.run(chat_async())
    except KeyboardInterrupt:
        print("\n\nç¨‹åºå·²ä¸­æ–­ã€‚å†è§ï¼")


if __name__ == "__main__":
    chat()

